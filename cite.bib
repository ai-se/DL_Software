@article{buda2018systematic,
  title={A systematic study of the class imbalance problem in convolutional neural networks},
  author={Buda, Mateusz and Maki, Atsuto and Mazurowski, Maciej A},
  journal={Neural Networks},
  volume={106},
  pages={249--259},
  year={2018},
  publisher={Elsevier}
}
@article{agrawal2020simpler,
  title={Simpler Hyperparameter Optimization for Software Analytics: Why, How, When?},
  author={Agrawal, Amritanshu and Yang, Xueqi and Agrawal, Rishabh and Shen, Xipeng and Menzies, Tim},
  journal={arXiv preprint arXiv:2008.07334},
  year={2020}
}
@article{koenig2011absolute,
  title={The absolute threshold of cone vision},
  author={Koenig, Darren and Hofer, Heidi},
  journal={Journal of vision},
  volume={11},
  number={1},
  pages={21--21},
  year={2011},
  publisher={The Association for Research in Vision and Ophthalmology}
}
@article{lecun2015deep,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={nature},
  volume={521},
  number={7553},
  pages={436--444},
  year={2015},
  publisher={Nature Publishing Group}
}
@book{green1966signal,
  title={Signal detection theory and psychophysics},
  author={Green, David Marvin and Swets, John A and others},
  volume={1},
  year={1966},
  publisher={Wiley New York}
}
@inproceedings{agrawal2018better,
  title={Is better data better than better data miners?: on the benefits of tuning SMOTE for defect prediction},
  author={Agrawal, Amritanshu and Menzies, Tim},
  booktitle={International Conference on Software Engineering},
  year={2018}
}
@article{hinton2009deep,
  title={Deep belief networks},
  author={Hinton, Geoffrey E},
  journal={Scholarpedia},
  volume={4},
  number={5},
  pages={5947},
  year={2009}
}

@inproceedings{hall00, author = {Hall, Mark A.}, title = {Correlation-Based Feature Selection for Discrete and Numeric Class Machine Learning}, year = {2000}, isbn = {1558607072}, publisher = {Morgan Kaufmann Publishers Inc.}, address = {San Francisco, CA, USA}, booktitle = {Proceedings of the Seventeenth International Conference on Machine Learning}, pages = {359–366}, numpages = {8}, series = {ICML ’00} }


@article{Chawla02, author = {Chawla, Nitesh V. and Bowyer, Kevin W. and Hall, Lawrence O. and Kegelmeyer, W. Philip}, title = {SMOTE: Synthetic Minority over-Sampling Technique}, year = {2002}, issue_date = {January 2002}, publisher = {AI Access Foundation}, address = {El Segundo, CA, USA}, volume = {16}, number = {1}, issn = {1076-9757}, journal = {J. Artif. Int. Res.}, month = jun, pages = {321–357}, numpages = {37} }


@article{menzies2003data,
  title={Data mining for very busy people},
  author={Menzies, Tim and Hu, Ying},
  journal={Computer},
  volume={36},
  number={11},
  pages={22--29},
  year={2003},
  publisher={IEEE}
}


@inproceedings{hassan2008road,
  title={The road ahead for mining software repositories},
  author={Hassan, Ahmed E},
  booktitle={2008 Frontiers of Software Maintenance},
  pages={48--57},
  year={2008},
  organization={IEEE}
}


@article{robillard2009recommendation,
  title={Recommendation systems for software engineering},
  author={Robillard, Martin and Walker, Robert and Zimmermann, Thomas},
  journal={IEEE software},
  volume={27},
  number={4},
  pages={80--86},
  year={2009},
  publisher={IEEE}
}


@article{menzies2006data,
  title={Data mining static code attributes to learn defect predictors},
  author={Menzies, Tim and Greenwald, Jeremy and Frank, Art},
  journal={IEEE transactions on software engineering},
  volume={33},
  number={1},
  pages={2--13},
  year={2006},
  publisher={IEEE}
}

@inproceedings{kim2016emerging,
  title={The emerging role of data scientists on software development teams},
  author={Kim, Miryung and Zimmermann, Thomas and DeLine, Robert and Begel, Andrew},
  booktitle={Proceedings of the 38th International Conference on Software Engineering},
  pages={96--107},
  year={2016},
  organization={ACM}
}

@article{menzies2018software,
  title={Software Analytics: What's Next?},
  author={Menzies, Tim and Zimmermann, Thomas},
  journal={IEEE Software},
  volume={35},
  number={5},
  pages={64--70},
  year={2018},
  publisher={IEEE}
}

@article{moeyersoms2015comprehensible,
  title={Comprehensible software fault and effort prediction: A data mining approach},
  author={Moeyersoms, Julie and de Fortuny, Enric Junqu{\'e} and Dejaeger, Karel and Baesens, Bart and Martens, David},
  journal={Journal of Systems and Software},
  volume={100},
  pages={80--90},
  year={2015},
  publisher={Elsevier}
}

@inproceedings{Novielli:2018,
 author = {Novielli, Nicole and Girardi, Daniela and Lanubile, Filippo},
 title = {A Benchmark Study on Sentiment Analysis for Software Engineering Research},
 booktitle = {Proceedings of the 15th International Conference on Mining Software Repositories},
 series = {MSR '18},
  isbn = {978-1-4503-5716-6},
 location = {Gothenburg, Sweden},
 pages = {364--375},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/3196398.3196403},
 doi = {10.1145/3196398.3196403},
 acmid = {3196403},
 publisher = {ACM},
 keywords = {NLP, communication channels, sentiment analysis, social software engineering},
} 


@inproceedings{tantithamthavorn2016automated,
  title={Automated parameter optimization of classification techniques for defect prediction models},
  author={Tantithamthavorn, Chakkrit and McIntosh, Shane and Hassan, Ahmed E and Matsumoto, Kenichi},
  booktitle={2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)},
  pages={321--332},
  year={2016},
  organization={IEEE}
}


@inproceedings{last2003data,
  title={The data mining approach to automated software testing},
  author={Last, Mark and Friedman, Menahem and Kandel, Abraham},
  booktitle={Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining},
  pages={388--396},
  year={2003},
  organization={ACM}
}

@article{fu2016tuning,
  title={Tuning for software analytics: Is it really necessary?},
  author={Fu, Wei and Menzies, Tim and Shen, Xipeng},
  journal={Information and Software Technology},
  volume={76},
  pages={135--146},
  year={2016},
  publisher={Elsevier}
}

@article{Binkley:2018,
 author = {Binkley, Dave and Lawrie, Dawn and Morrell, Christopher},
 title = {The Need for Software Specific Natural Language Techniques},
 journal = {Empirical Softw. Engg.},
 issue_date = {August    2018},
 volume = {23},
 number = {4},
 month = aug,
 year = {2018},
 issn = {1382-3256},
 pages = {2398--2425},
 numpages = {28},
 url = {https://doi.org/10.1007/s10664-017-9566-5},
 doi = {10.1007/s10664-017-9566-5},
 acmid = {3238611},
 publisher = {Kluwer Academic Publishers},
 address = {Norwell, MA, USA},
 keywords = {Feature location, Information need, Information retrieval, Query quality, Test collection challenge},
} 

@InProceedings{Cui_2019_CVPR,
author = {Cui, Yin and Jia, Menglin and Lin, Tsung-Yi and Song, Yang and Belongie, Serge},
title = {Class-Balanced Loss Based on Effective Number of Samples},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2019}
}



@article{Hoang2019,
abstract = {Software quality assurance efforts often focus on identifying defective code. To find likely defective code early, change-level defect prediction-aka. Just-In-Time (JIT) defect prediction-has been proposed. JIT defect prediction models identify likely defective changes and they are trained using machine learning techniques with the assumption that historical changes are similar to future ones. Most existing JIT defect prediction approaches make use of manually engineered features. Unlike those approaches, in this paper, we propose an end-to-end deep learning framework, named DeepJIT, that automatically extracts features from commit messages and code changes and use them to identify defects. Experiments on two popular software projects (i.e., QT and OPENSTACK) on three evaluation settings (i.e., cross-validation, short-period, and long-period) show that the best variant of DeepJIT (DeepJIT-Combined), compared with the best performing state-of-the-art approach, achieves improvements of 10.36-11.02{\%} for the project QT and 9.51-13.69{\%} for the project OPENSTACK in terms of the Area Under the Curve (AUC).},
author = {Hoang, Thong and {Khanh Dam}, Hoa and Kamei, Yasutaka and Lo, David and Ubayashi, Naoyasu},
doi = {10.1109/msr.2019.00016},
file = {:Users/ryedida/Library/Application Support/Mendeley Desktop/Downloaded/Hoang et al. - 2019 - DeepJIT An End-to-End Deep Learning Framework for Just-in-Time Defect Prediction.pdf:pdf},
journal = {2019 IEEE/ACM 16th International Conference on Mining Software Repositories (MSR)},
mendeley-groups = {Software Engineering},
pages = {34--45},
publisher = {IEEE},
title = {{DeepJIT: An End-to-End Deep Learning Framework for Just-in-Time Defect Prediction}},
year = {2019}
}


@inproceedings{white2016deep,
  title={Deep learning code fragments for code clone detection},
  author={White, Martin and Tufano, Michele and Vendome, Christopher and Poshyvanyk, Denys},
  booktitle={Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering},
  pages={87--98},
  year={2016},
  organization={ACM}
}

@inproceedings{nguyen2017exploring,
  title={Exploring API embedding for API usages and applications},
  author={Nguyen, Trong Duc and Nguyen, Anh Tuan and Phan, Hung Dang and Nguyen, Tien N},
  booktitle={2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)},
  pages={438--449},
  year={2017},
  organization={IEEE}
}

@article{deb2005evaluating,
  title={Evaluating the $\varepsilon$-domination based multi-objective evolutionary algorithm for a quick computation of Pareto-optimal solutions},
  author={Deb, Kalyanmoy and Mohan, Manikanth and Mishra, Shikhar},
  journal={Evolutionary computation},
  volume={13},
  number={4},
  pages={501--525},
  year={2005},
  publisher={MIT Press}
}


@inproceedings{zhao2018deepsim,
  title={Deepsim: deep learning code functional similarity},
  author={Zhao, Gang and Huang, Jeff},
  booktitle={Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
  pages={141--151},
  year={2018},
  organization={ACM}
}

% from lit review
@article{choetkiertikul2018deep,
  title={A deep learning model for estimating story points},
  author={Choetkiertikul, Morakot and Dam, Hoa Khanh and Tran, Truyen and Pham, Trang Thi Minh and Ghose, Aditya and Menzies, Tim},
  journal={IEEE Transactions on Software Engineering},
  year={2018},
  publisher={IEEE}
}


@article{huo2019deep,
  title={Deep transfer bug localization},
  author={Huo, Xuan and Thung, Ferdian and Li, Ming and Lo, David and Shi, Shu-Ting},
  journal={IEEE Transactions on Software Engineering},
  year={2019},
  publisher={IEEE}
}

@inproceedings{gu2016deep,
  title={Deep API learning},
  author={Gu, Xiaodong and Zhang, Hongyu and Zhang, Dongmei and Kim, Sunghun},
  booktitle={Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering},
  pages={631--642},
  year={2016},
  organization={ACM}
}

@article{chen2019mining,
  title={Mining likely analogical apis across third-party libraries via large-scale unsupervised api semantics embedding},
  author={Chen, Chunyang and Xing, Zhenchang and Liu, Yang and Ong, Kent Long Xiong},
  journal={IEEE Transactions on Software Engineering},
  year={2019},
  publisher={IEEE}
}


@article{li2018deep,
  title={Deep Learning in Software Engineering},
  author={Li, Xiaochen and Jiang, He and Ren, Zhilei and Li, Ge and Zhang, Jingxuan},
  journal={arXiv preprint arXiv:1805.04825},
  year={2018}
}

@inproceedings{lin2018sentiment,
  title={Sentiment analysis for software engineering: How far can we go?},
  author={Lin, Bin and Zampetti, Fiorella and Bavota, Gabriele and Di Penta, Massimiliano and Lanza, Michele and Oliveto, Rocco},
  booktitle={2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)},
  pages={94--104},
  year={2018},
  organization={IEEE}
}


@inproceedings{guo2017semantically,
  title={Semantically enhanced software traceability using deep learning techniques},
  author={Guo, Jin and Cheng, Jinghui and Cleland-Huang, Jane},
  booktitle={2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)},
  pages={3--14},
  year={2017},
  organization={IEEE}
}

@article{kim2008classifying,
  title={Classifying software changes: Clean or buggy?},
  author={Kim, Sunghun and Whitehead Jr, E James and Zhang, Yi},
  journal={IEEE Transactions on Software Engineering},
  volume={34},
  number={2},
  pages={181--196},
  year={2008},
  publisher={IEEE}
}


@article{misirli2011ai,
  title={Ai-based software defect predictors: Applications and
benefits in a case study},
  author={Misirli, A. T. and Bener, A. and Kale, R.},
  journal={AI Magazine},
  year={2011}
}


@inproceedings{rahman2014comparing,
  title={Comparing static bug finders and statistical prediction},
  author={Rahman, F. and Khatri, S. and Barr, E. T and
Devanbu, P.},
  booktitle={ICSE},
  year={2014},
  organization={ACM}
}


@inproceedings{arcuri11, author = {Arcuri, Andrea and Briand, Lionel}, title = {A Practical Guide for Using Statistical Tests to Assess Randomized Algorithms in Software Engineering}, year = {2011}, isbn = {9781450304450}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/1985793.1985795}, doi = {10.1145/1985793.1985795}, booktitle = {Proceedings of the 33rd International Conference on Software Engineering}, pages = {1–10}, numpages = {10}, keywords = {effect size, non-parametric test, parametric test, statistical difference, survey, bonferroni adjustment, confidence interval, systematic review}, location = {Waikiki, Honolulu, HI, USA}, series = {ICSE ’11} }


@ARTICLE{wan18,
author={Z. Wan and X. Xia and A. E. Hassan and D. Lo and J. Yin and X. Yang},
journal={IEEE Transactions Software Engineering},
title={Perceptions, Expectations, \& Challenges in Defect Prediction},
year={2018},
}

@article{briand1993developing,
  title={Developing interpretable models with optimized set reduction for identifying high-risk software components},
  author={Briand, Lionel C and Brasili, VR and Hetmanski, Christopher J},
  journal={IEEE Transactions on Software Engineering},
  volume={19},
  number={11},
  pages={1028--1044},
  year={1993},
  publisher={IEEE}
}

@article{Li2017,
abstract = {Programmers produce code clones when developing software. By copying and pasting code with or without modification, developers reuse existing code to improve programming productivity. However, code clones present challenges to software maintenance: they may require consistent application of the same or similar bug fixes or program changes to multiple code locations. To simplify the maintenance process, various tools have been proposed to automatically detect clones [1], [2], [3], [4], [5], [6]. Some tools tokenize source code, and then compare the sequence or frequency of tokens to reveal clones [1], [3], [4], [5]. Some other tools detect clones using tree-matching algorithms to compare the Abstract Syntax Trees (ASTs) of source code [2], [6]. In this paper, we present CCLEARNER, the first solely token-based clone detection approach leveraging deep learning. CCLEARNER extracts tokens from known method-level code clones and nonclones to train a classifier, and then uses the classifier to detect clones in a given codebase.To evaluate CCLEARNER, we reused BigCloneBench [7], an existing large benchmark of real clones. We used part of the benchmark for training and the other part for testing, and observed that CCLEARNER effectively detected clones. With the same data set, we conducted the first systematic comparison experiment between CCLEARNER and three popular clone detection tools. Compared with the approaches not using deep learning, CCLEARNER achieved competitive clone detection effectiveness with low time cost.},
author = {Li, Liuqing and Feng, He and Zhuang, Wenjie and Meng, Na and Ryder, Barbara},
doi = {10.1109/ICSME.2017.46},
file = {:Users/ryedida/Library/Application Support/Mendeley Desktop/Downloaded/Li et al. - 2017 - CCLearner A deep learning-based clone detection approach.pdf:pdf},
isbn = {9781538609927},
journal = {Proceedings - 2017 IEEE International Conference on Software Maintenance and Evolution, ICSME 2017},
keywords = {Clone detection,Deep learning,Empirical},
mendeley-groups = {Software Engineering},
pages = {249--260},
title = {{CCLearner: A deep learning-based clone detection approach}},
year = {2017}
}
@article{Tufano2018,
abstract = {Assessing the similarity between code components plays a pivotal role in a number of Software Engineering (SE) tasks, such as clone detection, impact analysis, refactoring, etc. Code similarity is gen-erally measured by relying on manually defined or hand-crafted features, e.g., by analyzing the overlap among identifiers or com-paring the Abstract Syntax Trees of two code components. These features represent a best guess at what SE researchers can utilize to exploit and reliably assess code similarity for a given task. Recent work has shown, when using a stream of identifiers to represent the code, that Deep Learning (DL) can effectively replace manual feature engineering for the task of clone detection. However, source code can be represented at different levels of abstraction: identi-fiers, Abstract Syntax Trees, Control Flow Graphs, and Bytecode. We conjecture that each code representation can provide a different, yet orthogonal view of the same code fragment, thus, enabling a more reliable detection of similarities in code. In this paper, we demonstrate how SE tasks can benefit from a DL-based approach, which can automatically learn code similarities from different rep-resentations.},
author = {Tufano, Michele and Watson, Cody and Bavota, Gabriele and {Di Penta}, Massimiliano and White, Martin and Poshyvanyk, Denys},
doi = {10.1145/3196398.3196431},
file = {:Users/ryedida/Library/Application Support/Mendeley Desktop/Downloaded/Tufano et al. - 2018 - Deep learning similarities from different representations of source code.pdf:pdf},
isbn = {9781450357166},
issn = {02705257},
journal = {Proceedings - International Conference on Software Engineering},
keywords = {code similarities,deep learning,neural networks},
mendeley-groups = {Software Engineering},
pages = {542--553},
publisher = {ACM},
title = {{Deep learning similarities from different representations of source code}},
year = {2018}
}
@article{White2016,
abstract = {Code clone detection is an important problem for software maintenance and evolution. Many approaches consider ei-ther structure or identifiers, but none of the existing detec-tion techniques model both sources of information. These techniques also depend on generic, handcrafted features to represent code fragments. We introduce learning-based de-tection techniques where everything for representing terms and fragments in source code is mined from the repository. Our code analysis supports a framework, which relies on deep learning, for automatically linking patterns mined at the lexical level with patterns mined at the syntactic level. We evaluated our novel learning-based approach for code clone detection with respect to feasibility from the point of view of software maintainers. We sampled and manually evaluated 398 file-and 480 method-level pairs across eight real-world Java systems; 93{\%} of the file-and method-level samples were evaluated to be true positives. Among the true positives, we found pairs mapping to all four clone types. We compared our approach to a traditional structure-oriented technique and found that our learning-based approach de-tected clones that were either undetected or suboptimally reported by the prominent tool Deckard. Our results affirm that our learning-based approach is suitable for clone detec-tion and a tenable technique for researchers.},
author = {White, Martin and Tufano, Michele and Vendome, Christopher and Poshyvanyk, Denys},
doi = {10.1145/2970276.2970326},
file = {:Users/ryedida/Library/Application Support/Mendeley Desktop/Downloaded/White et al. - 2016 - Deep learning code fragments for code clone detection.pdf:pdf},
isbn = {9781450338455},
journal = {ASE 2016 - Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering},
keywords = {Abstract syntax trees,Code clone detection,Deep learning,Language models,Machine learning,Neu-ral networks},
mendeley-groups = {Software Engineering},
pages = {87--98},
title = {{Deep learning code fragments for code clone detection}},
year = {2016}
}
@article{Wang2016,
abstract = {Software defect prediction, which predicts defective code regions, can help developers find bugs and prioritize their testing efforts. To build accurate prediction models, previous studies focus on manually designing features that encode the characteristics of programs and exploring different machine learning algorithms. Existing traditional features often fail to capture the semantic differences of programs, and such a capability is needed for building accurate prediction models. To bridge the gap between programs' semantics and defect prediction features, this paper proposes to leverage a powerful representation-learning algorithm, deep learning, to learn semantic representation of programs automatically from source code. Specifically, we leverage Deep Belief Network (DBN) to automatically learn semantic features from token vectors extracted from programs' Abstract Syntax Trees (ASTs). Our evaluation on ten open source projects shows that our automatically learned semantic features significantly improve both within-project defect prediction (WPDP) and cross-project defect prediction (CPDP) compared to traditional features. Our semantic features improve WPDP on average by 14.7{\%} in precision, 11.5{\%} in recall, and 14.2{\%} in F1. For CPDP, our semantic features based approach outperforms the state-of-the-art technique TCA+ with traditional features by 8.9{\%} in F1.},
author = {Wang, Song and Liu, Taiyue and Tan, Lin},
doi = {10.1145/2884781.2884804},
file = {:Users/ryedida/Library/Application Support/Mendeley Desktop/Downloaded/Wang, Liu, Tan - 2016 - Automatically learning semantic features for defect prediction.pdf:pdf},
isbn = {9781450339001},
issn = {02705257},
journal = {Proceedings - International Conference on Software Engineering},
mendeley-groups = {Software Engineering},
pages = {297--308},
publisher = {ACM},
title = {{Automatically learning semantic features for defect prediction}},
volume = {14-22-May-},
year = {2016}
}

@ARTICLE{Lessmann08,
  author={S. {Lessmann} and B. {Baesens} and C. {Mues} and S. {Pietsch}},
  journal={IEEE Transactions on Software Engineering}, 
  title={Benchmarking Classification Models for Software Defect Prediction: A Proposed Framework and Novel Findings}, 
  year={2008},
  volume={34},
  number={4},
  pages={485-496},}


@article{Dam2019,
abstract = {Defects are common in software systems and can potentially cause various problems to software users. Different methods have been developed to quickly predict the most likely locations of defects in large code bases. Most of them focus on designing features (e.g. complexity metrics) that correlate with potentially defective code. Those approaches however do not sufficiently capture the syntax and different levels of semantics of source code, an important capability for building accurate prediction models. In this paper, we develop a novel prediction model which is capable of automatically learning features for representing source code and using them for defect prediction. Our prediction system is built upon the powerful deep learning, tree-structured Long Short Term Memory network which directly matches with the Abstract Syntax Tree representation of source code. An evaluation on two datasets, one from open source projects contributed by Samsung and the other from the public PROMISE repository, demonstrates the effectiveness of our approach for both within-project and cross-project predictions.},
author = {Dam, Hoa Khanh and Pham, Trang and Ng, Shien Wee and Tran, Truyen and Grundy, John and Ghose, Aditya and Kim, Taeksu and Kim, Chul-Joo},
doi = {10.1109/msr.2019.00017},
file = {:Users/ryedida/Library/Application Support/Mendeley Desktop/Downloaded/Dam et al. - 2019 - Lessons Learned from Using a Deep Tree-Based Model for Software Defect Prediction in Practice.pdf:pdf},
journal = {2019 IEEE/ACM 16th International Conference on Mining Software Repositories (MSR)},
mendeley-groups = {Software Engineering},
pages = {46--57},
publisher = {IEEE},
title = {{Lessons Learned from Using a Deep Tree-Based Model for Software Defect Prediction in Practice}},
year = {2019}
}
@article{Dam2018,
author = {Dam, Hoa Khanh and Tran, Truyen and Pham, Trang Thi Minh and Ng, Shien Wee and Grundy, John and Ghose, Aditya},
doi = {10.1109/TSE.2018.2881961},
file = {:Users/ryedida/Library/Application Support/Mendeley Desktop/Downloaded/Dam et al. - 2018 - Automatic feature learning for predicting vulnerable software components.pdf:pdf},
issn = {19393520},
journal = {IEEE Transactions on Software Engineering},
keywords = {Empirical software engineering,Feature extraction,Mining software engineering repositories,Predictive models,Security,Semantics,Software systems,Software vulnerability prediction,System recovery},
mendeley-groups = {Software Engineering},
number = {8},
pages = {1--19},
title = {{Automatic feature learning for predicting vulnerable software components}},
volume = {14},
year = {2018}
}
@article{Fu2017,
abstract = {While deep learning is an exciting new technique, the benefits of this method need to be assessed with respect to its computational cost. This is particularly important for deep learning since these learners need hours (to weeks) to train the model. Such long training time limits the ability of (a){\~{}}a researcher to test the stability of their conclusion via repeated runs with different random seeds; and (b){\~{}}other researchers to repeat, improve, or even refute that original work. For example, recently, deep learning was used to find which questions in the Stack Overflow programmer discussion forum can be linked together. That deep learning system took 14 hours to execute. We show here that applying a very simple optimizer called DE to fine tune SVM, it can achieve similar (and sometimes better) results. The DE approach terminated in 10 minutes; i.e. 84 times faster hours than deep learning method. We offer these results as a cautionary tale to the software analytics community and suggest that not every new innovation should be applied without critical analysis. If researchers deploy some new and expensive process, that work should be baselined against some simpler and faster alternatives.},
author = {Fu, Wei and Menzies, Tim},
doi = {10.1145/3106237.3106256},
file = {:Users/ryedida/Library/Application Support/Mendeley Desktop/Downloaded/Fu, Menzies - 2017 - Easy over hard A case study on deep learning.pdf:pdf},
isbn = {9781450351058},
journal = {Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering},
keywords = {data analytics for software,deep learning,differential evolution,engineering,parameter,search based software engineering,software analytics,svm,tuning},
mendeley-groups = {Software Engineering},
pages = {49--60},
title = {{Easy over hard: A case study on deep learning}},
volume = {Part F1301},
year = {2017}
}
@inproceedings{li2018visualizing,
  title={Visualizing the loss landscape of neural nets},
  author={Li, Hao and Xu, Zheng and Taylor, Gavin and Studer, Christoph and Goldstein, Tom},
  booktitle={Advances in Neural Information Processing Systems},
  pages={6389--6399},
  year={2018}
}
@article{zou2018stochastic,
  title={Stochastic gradient descent optimizes over-parameterized deep relu networks},
  author={Zou, Difan and Cao, Yuan and Zhou, Dongruo and Gu, Quanquan},
  journal={arXiv preprint arXiv:1811.08888},
  year={2018}
}
@article{loshchilov2016cma,
  title={CMA-ES for hyperparameter optimization of deep neural networks},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1604.07269},
  year={2016}
}
@article{bengio2000gradient,
  title={Gradient-based optimization of hyperparameters},
  author={Bengio, Yoshua},
  journal={Neural computation},
  volume={12},
  number={8},
  pages={1889--1900},
  year={2000},
  publisher={MIT Press}
}
@article{bergstra2012random,
  title={Random search for hyper-parameter optimization},
  author={Bergstra, James and Bengio, Yoshua},
  journal={Journal of machine learning research},
  volume={13},
  number={Feb},
  pages={281--305},
  year={2012}
}
@article{agrawal2019dodge,
  title={How to" DODGE" Complex Software Analytics},
  author={Agrawal, Amritanshu and Fu, Wei and Chen, Di and Shen, Xipeng and Menzies, Tim},
  journal={IEEE Transactions on Software Engineering},
  year={2019},
  publisher={IEEE}
}
@article{agrawal2018wrong,
  title={What is wrong with topic modeling? and how to fix it using search-based software engineering},
  author={Agrawal, Amritanshu and Fu, Wei and Menzies, Tim},
  journal={Information and Software Technology},
  volume={98},
  pages={74--88},
  year={2018},
  publisher={Elsevier}
}
@misc{Sayyad-Shirabad+Menzies:2005 ,
author = "Sayyad Shirabad, J. and Menzies, T.J.",
year = "2005",
title = "{The {PROMISE} Repository of Software Engineering Databases.}",
url = "http://promise.site.uottawa.ca/SERepository",
howpublished = "School of Information Technology and Engineering, University of Ottawa, Canada"}
@article{chidamber1994metrics,
  title={A metrics suite for object oriented design},
  author={Chidamber, Shyam R and Kemerer, Chris F},
  journal={IEEE Transactions on software engineering},
  volume={20},
  number={6},
  pages={476--493},
  year={1994},
  publisher={IEEE}
}
@article{henderson1996coupling,
  title={Coupling and cohesion (towards a valid metrics suite for object-oriented analysis and design)},
  author={Henderson-Sellers, Brian and Constantine, Larry L and Graham, Ian M},
  journal={Object oriented systems},
  volume={3},
  number={3},
  pages={143--158},
  year={1996}
}
@article{bansiya2002hierarchical,
  title={A hierarchical model for object-oriented design quality assessment},
  author={Bansiya, Jagdish and Davis, Carl G.},
  journal={IEEE Transactions on software engineering},
  volume={28},
  number={1},
  pages={4--17},
  year={2002},
  publisher={IEEE}
}
@inproceedings{tang1999empirical,
  title={An empirical study on object-oriented metrics},
  author={Tang, Mei-Huei and Kao, Ming-Hung and Chen, Mei-Hwa},
  booktitle={Proceedings sixth international software metrics symposium (Cat. No. PR00403)},
  pages={242--249},
  year={1999},
  organization={IEEE}
}
@article{martin1994oo,
  title={OO design quality metrics},
  author={Martin, Robert},
  journal={An analysis of dependencies},
  volume={12},
  number={1},
  pages={151--170},
  year={1994}
}
@article{mccabe1976complexity,
  title={A complexity measure},
  author={McCabe, Thomas J},
  journal={IEEE Transactions on software Engineering},
  number={4},
  pages={308--320},
  year={1976},
  publisher={IEEE}
}
@article{scikit-learn,
 title={Scikit-learn: Machine Learning in {P}ython},
 author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal={Journal of Machine Learning Research},
 volume={12},
 pages={2825--2830},
 year={2011}
}
@article{rosenthal1994parametric,
  title={Parametric measures of effect size},
  author={Rosenthal, Robert and Cooper, Harris and Hedges, L},
  journal={The handbook of research synthesis},
  volume={621},
  number={2},
  pages={231--244},
  year={1994}
}
@inproceedings{montufar2014number,
  title={On the number of linear regions of deep neural networks},
  author={Montufar, Guido F and Pascanu, Razvan and Cho, Kyunghyun and Bengio, Yoshua},
  booktitle={Advances in neural information processing systems},
  pages={2924--2932},
  year={2014}
}
@inproceedings{lin2017focal,
  title={Focal loss for dense object detection},
  author={Lin, Tsung-Yi and Goyal, Priya and Girshick, Ross and He, Kaiming and Doll{\'a}r, Piotr},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2980--2988},
  year={2017}
}
@inproceedings{zhang2018neural,
  title={A Neural Language Model with a Modified Attention Mechanism for Software Code},
  author={Zhang, Xian and Ben, Kerong},
  booktitle={2018 IEEE 9th International Conference on Software Engineering and Service Science (ICSESS)},
  pages={232--236},
  year={2018},
  organization={IEEE}
}
@article{wang2018deep,
  title={Deep semantic feature learning for software defect prediction},
  author={Wang, Song and Liu, Taiyue and Nam, Jaechang and Tan, Lin},
  journal={IEEE Transactions on Software Engineering},
  year={2018},
  publisher={IEEE}
}
@inproceedings{pham2019cradle,
  title={CRADLE: cross-backend validation to detect and localize bugs in deep learning libraries},
  author={Pham, Hung Viet and Lutellier, Thibaud and Qi, Weizhen and Tan, Lin},
  booktitle={2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)},
  pages={1027--1038},
  year={2019},
  organization={IEEE}
}
@article{wen2018well,
  title={How well do change sequences predict defects? sequence learning from software changes},
  author={Wen, Ming and Wu, Rongxin and Cheung, Shing-Chi},
  journal={IEEE Transactions on Software Engineering},
  year={2018},
  publisher={IEEE}
}
@inproceedings{hoang2019deepjit,
  title={DeepJIT: an end-to-end deep learning framework for just-in-time defect prediction},
  author={Hoang, Thong and Dam, Hoa Khanh and Kamei, Yasutaka and Lo, David and Ubayashi, Naoyasu},
  booktitle={2019 IEEE/ACM 16th International Conference on Mining Software Repositories (MSR)},
  pages={34--45},
  year={2019},
  organization={IEEE}
}
@inproceedings{li2017cclearner,
  title={Cclearner: A deep learning-based clone detection approach},
  author={Li, Liuqing and Feng, He and Zhuang, Wenjie and Meng, Na and Ryder, Barbara},
  booktitle={2017 IEEE International Conference on Software Maintenance and Evolution (ICSME)},
  pages={249--260},
  year={2017},
  organization={IEEE}
}
@inproceedings{deshmukh2017towards,
  title={Towards accurate duplicate bug retrieval using deep learning techniques},
  author={Deshmukh, Jayati and Podder, Sanjay and Sengupta, Shubhashis and Dubash, Neville and others},
  booktitle={2017 IEEE International conference on software maintenance and evolution (ICSME)},
  pages={115--124},
  year={2017},
  organization={IEEE}
}
@inproceedings{koch2015siamese,
  title={Siamese neural networks for one-shot image recognition},
  author={Koch, Gregory and Zemel, Richard and Salakhutdinov, Ruslan},
  booktitle={ICML deep learning workshop},
  volume={2},
  year={2015},
  organization={Lille}
}
@inproceedings{wang2016automatically,
  title={Automatically learning semantic features for defect prediction},
  author={Wang, Song and Liu, Taiyue and Tan, Lin},
  booktitle={2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)},
  pages={297--308},
  year={2016},
  organization={IEEE}
}
@inproceedings{robbes2019leveraging,
  title={Leveraging small software engineering data sets with pre-trained neural networks},
  author={Robbes, Romain and Janes, Andrea},
  booktitle={2019 IEEE/ACM 41st International Conference on Software Engineering: New Ideas and Emerging Results (ICSE-NIER)},
  pages={29--32},
  year={2019},
  organization={IEEE}
}
@article{howard2018universal,
  title={Universal language model fine-tuning for text classification},
  author={Howard, Jeremy and Ruder, Sebastian},
  journal={arXiv preprint arXiv:1801.06146},
  year={2018}
}
@inproceedings{dam2019lessons,
  title={Lessons learned from using a deep tree-based model for software defect prediction in practice},
  author={Dam, Hoa Khanh and Pham, Trang and Ng, Shien Wee and Tran, Truyen and Grundy, John and Ghose, Aditya and Kim, Taeksu and Kim, Chul-Joo},
  booktitle={2019 IEEE/ACM 16th International Conference on Mining Software Repositories (MSR)},
  pages={46--57},
  year={2019},
  organization={IEEE}
}
@article{tai2015improved,
  title={Improved semantic representations from tree-structured long short-term memory networks},
  author={Tai, Kai Sheng and Socher, Richard and Manning, Christopher D},
  journal={arXiv preprint arXiv:1503.00075},
  year={2015}
}
@article{wan2018perceptions,
  title={Perceptions, expectations, and challenges in defect prediction},
  author={Wan, Zhiyuan and Xia, Xin and Hassan, Ahmed E and Lo, David and Yin, Jianwei and Yang, Xiaohu},
  journal={IEEE Transactions on Software Engineering},
  year={2018},
  publisher={IEEE}
}
@inproceedings{ghotra2015revisiting,
  title={Revisiting the impact of classification techniques on the performance of defect prediction models},
  author={Ghotra, Baljinder and McIntosh, Shane and Hassan, Ahmed E},
  booktitle={2015 IEEE/ACM 37th IEEE International Conference on Software Engineering},
  volume={1},
  pages={789--800},
  year={2015},
  organization={IEEE}
}
@article{majumder2019learning,
  title={Learning GENERAL Principles from Hundreds of Software Projects},
  author={Majumder, Suvodeep and Krishna, Rahul and Menzies, Tim},
  journal={arXiv preprint arXiv:1911.04250},
  year={2019}
}
@inproceedings{santurkar2018does,
  title={How does batch normalization help optimization?},
  author={Santurkar, Shibani and Tsipras, Dimitris and Ilyas, Andrew and Madry, Aleksander},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2483--2493},
  year={2018}
}

@inproceedings{kim2015remi,
  title={REMI: defect prediction for efficient API testing},
  author={Kim, Mijung and Nam, Jaechang and Yeon, Jaehyuk and Choi, Soonhwang and Kim, Sunghun},
  booktitle={Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering},
  pages={990--993},
  year={2015}
}
@inproceedings{white2015toward,
  title={Toward deep learning software repositories},
  author={White, Martin and Vendome, Christopher and Linares-V{\'a}squez, Mario and Poshyvanyk, Denys},
  booktitle={2015 IEEE/ACM 12th Working Conference on Mining Software Repositories},
  pages={334--345},
  year={2015},
  organization={IEEE}
}

@article{holmes03, author = {Hall, Mark A. and Holmes, Geoffrey}, title = {Benchmarking Attribute Selection Techniques for Discrete Class Data Mining}, year = {2003}, issue_date = {November 2003}, publisher = {IEEE Educational Activities Department}, address = {USA}, volume = {15}, number = {6}, issn = {1041-4347}, url = {https://doi.org/10.1109/TKDE.2003.1245283}, doi = {10.1109/TKDE.2003.1245283}, journal = {IEEE Trans. on Knowl. and Data Eng.}, month = nov, pages = {1437–1447}, numpages = {11}, keywords = {benchmarking., Attribute selection, classification} }

@inproceedings{han2017learning,
  title={Learning to predict severity of software vulnerability using only vulnerability description},
  author={Han, Zhuobing and Li, Xiaohong and Xing, Zhenchang and Liu, Hongtao and Feng, Zhiyong},
  booktitle={2017 IEEE International Conference on Software Maintenance and Evolution (ICSME)},
  pages={125--136},
  year={2017},
  organization={IEEE}
}
@inproceedings{pennington2014glove,
  title={Glove: Global vectors for word representation},
  author={Pennington, Jeffrey and Socher, Richard and Manning, Christopher D},
  booktitle={Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},
  pages={1532--1543},
  year={2014}
}
@article{marcus2018deep,
  title={Deep learning: A critical appraisal},
  author={Marcus, Gary},
  journal={arXiv preprint arXiv:1801.00631},
  year={2018}
}
@inproceedings{chen2018applications,
  title={Applications of psychological science for actionable analytics},
  author={Chen, Di and Fu, Wei and Krishna, Rahul and Menzies, Tim},
  booktitle={Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
  pages={456--467},
  year={2018}
}
@article{liu2019two,
  title={A two-phase transfer learning model for cross-project defect prediction},
  author={Liu, Chao and Yang, Dan and Xia, Xin and Yan, Meng and Zhang, Xiaohong},
  journal={Information and Software Technology},
  volume={107},
  pages={125--136},
  year={2019},
  publisher={Elsevier}
}
@article{mittas2012ranking,
  title={Ranking and clustering software cost estimation models through a multiple comparisons algorithm},
  author={Mittas, Nikolaos and Angelis, Lefteris},
  journal={IEEE Transactions on software engineering},
  volume={39},
  number={4},
  pages={537--551},
  year={2012},
  publisher={IEEE}
}
@inproceedings{arcuri2011practical,
  title={A practical guide for using statistical tests to assess randomized algorithms in software engineering},
  author={Arcuri, Andrea and Briand, Lionel},
  booktitle={2011 33rd International Conference on Software Engineering (ICSE)},
  pages={1--10},
  year={2011},
  organization={IEEE}
}
@article{ioffe2015batch,
  title={Batch normalization: Accelerating deep network training by reducing internal covariate shift},
  author={Ioffe, Sergey and Szegedy, Christian},
  journal={arXiv preprint arXiv:1502.03167},
  year={2015}
}
@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}
@article{dam2018automatic,
  title={Automatic feature learning for predicting vulnerable software components},
  author={Dam, Hoa Khanh and Tran, Truyen and Pham, Trang Thi Minh and Ng, Shien Wee and Grundy, John and Ghose, Aditya},
  journal={IEEE Transactions on Software Engineering},
  year={2018},
  publisher={IEEE}
}
@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}
@inproceedings{huang2017densely,
  title={Densely connected convolutional networks},
  author={Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4700--4708},
  year={2017}
}
@article{brown2020language,
  title={Language Models are Few-Shot Learners},
  author={Brown, Tom B and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={arXiv preprint arXiv:2005.14165},
  year={2020}
}
@article{menzies2003simple,
  title={How simple is software defect detection},
  author={Menzies, Tim and Ammar, Kareem and Nikora, Allen and DiStefano, Justin},
  journal={Submitted to the Emprical Software Engineering Journal},
  year={2003},
  publisher={Citeseer}
}
@phdthesis{province2015exploiting,
  title={Exploiting low dimensionality in software engineering},
  author={Province, B},
  year={2015},
  school={Master’s thesis, CSEE, West Virginia University}
}
@inproceedings{feurer2015efficient,
  title={Efficient and robust automated machine learning},
  author={Feurer, Matthias and Klein, Aaron and Eggensperger, Katharina and Springenberg, Jost and Blum, Manuel and Hutter, Frank},
  booktitle={Advances in neural information processing systems},
  pages={2962--2970},
  year={2015}
}
@inproceedings{thornton2013auto,
  title={Auto-WEKA: Combined selection and hyperparameter optimization of classification algorithms},
  author={Thornton, Chris and Hutter, Frank and Hoos, Holger H and Leyton-Brown, Kevin},
  booktitle={Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining},
  pages={847--855},
  year={2013}
}
@inproceedings{liu2019auto,
  title={Auto-deeplab: Hierarchical neural architecture search for semantic image segmentation},
  author={Liu, Chenxi and Chen, Liang-Chieh and Schroff, Florian and Adam, Hartwig and Hua, Wei and Yuille, Alan L and Fei-Fei, Li},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={82--92},
  year={2019}
}
@article{elsken2018neural,
  title={Neural architecture search: A survey},
  author={Elsken, Thomas and Metzen, Jan Hendrik and Hutter, Frank},
  journal={arXiv preprint arXiv:1808.05377},
  year={2018}
}
@article{bergstra2013making,
  title={Making a science of model search: Hyperparameter optimization in hundreds of dimensions for vision architectures},
  author={Bergstra, James and Yamins, Daniel and Cox, David Daniel},
  year={2013},
  publisher={Jmlr}
}
@inproceedings{domhan2015speeding,
  title={Speeding up automatic hyperparameter optimization of deep neural networks by extrapolation of learning curves},
  author={Domhan, Tobias and Springenberg, Jost Tobias and Hutter, Frank},
  booktitle={Twenty-Fourth International Joint Conference on Artificial Intelligence},
  year={2015}
}
@inproceedings{saxena2016convolutional,
  title={Convolutional neural fabrics},
  author={Saxena, Shreyas and Verbeek, Jakob},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4053--4061},
  year={2016}
}
@article{shahriari2015taking,
  title={Taking the human out of the loop: A review of Bayesian optimization},
  author={Shahriari, Bobak and Swersky, Kevin and Wang, Ziyu and Adams, Ryan P and De Freitas, Nando},
  journal={Proceedings of the IEEE},
  volume={104},
  number={1},
  pages={148--175},
  year={2015},
  publisher={IEEE}
}
@article{stanley2002evolving,
  title={Evolving neural networks through augmenting topologies},
  author={Stanley, Kenneth O and Miikkulainen, Risto},
  journal={Evolutionary computation},
  volume={10},
  number={2},
  pages={99--127},
  year={2002},
  publisher={MIT Press}
}
@inproceedings{ba2014deep,
  title={Do deep nets really need to be deep?},
  author={Ba, Jimmy and Caruana, Rich},
  booktitle={Advances in neural information processing systems},
  pages={2654--2662},
  year={2014}
}
@article{lee2020biobert,
  title={BioBERT: a pre-trained biomedical language representation model for biomedical text mining},
  author={Lee, Jinhyuk and Yoon, Wonjin and Kim, Sungdong and Kim, Donghyeon and Kim, Sunkyu and So, Chan Ho and Kang, Jaewoo},
  journal={Bioinformatics},
  volume={36},
  number={4},
  pages={1234--1240},
  year={2020},
  publisher={Oxford University Press}
}
@article{sharma2019bioflair,
  title={BioFLAIR: Pretrained Pooled Contextualized Embeddings for Biomedical Sequence Labeling Tasks},
  author={Sharma, Shreyas and Daniel Jr, Ron},
  journal={arXiv preprint arXiv:1908.05760},
  year={2019}
}
@article{honavar2005principles,
  title={Principles of Artificial Intelligence Fall 2005 Handout\# 2 Goal-Based Agents},
  author={Honavar, Vasant},
  year={2005}
}
@Article{Shin2013,
author="Shin, Y.
and Williams, L.",
title="Can traditional fault prediction models be used for vulnerability prediction?",
journal="EMSE",
year="2013",
abstract="Finding security vulnerabilities requires a different mindset than finding general faults in software---thinking like an attacker. Therefore, security engineers looking to prioritize security inspection and testing efforts may be better served by a prediction model that indicates security vulnerabilities rather than faults. At the same time, faults and vulnerabilities have commonalities that may allow development teams to use traditional fault prediction models and metrics for vulnerability prediction. The goal of our study is to determine whether fault prediction models can be used for vulnerability prediction or if specialized vulnerability prediction models should be developed when both models are built with traditional metrics of complexity, code churn, and fault history. We have performed an empirical study on a widely-used, large open source project, the Mozilla Firefox web browser, where 21{\%} of the source code files have faults and only 3{\%} of the files have vulnerabilities. Both the fault prediction model and the vulnerability prediction model provide similar ability in vulnerability prediction across a wide range of classification thresholds. For example, the fault prediction model provided recall of 83{\%} and precision of 11{\%} at classification threshold 0.6 and the vulnerability prediction model provided recall of 83{\%} and precision of 12{\%} at classification threshold 0.5. Our results suggest that fault prediction models based upon traditional metrics can substitute for specialized vulnerability prediction models. However, both fault prediction and vulnerability prediction models require significant improvement to reduce false positives while providing high recall.",
issn="1573-7616",
doi="10.1007/s10664-011-9190-8",
url="https://doi.org/10.1007/s10664-011-9190-8"
}
@article{menzies10dp,
 author = {Menzies, T. and Milton, Z. and Turhan, B. and Cukic, B. and Jiang, Y. and Bener, A.},
 title = {Defect Prediction from Static Code Features: Current Results, Limitations, New Approaches},
 journal = {ASE},
 year = {2010},
 keywords = {Defect prediction, Static code features, WHICH},
} 
@ARTICLE{menzies07dp, 
author={T. Menzies and J. Greenwald and A. Frank}, 
journal={TSE}, 
title={Data Mining Static Code Attributes to Learn Defect Predictors}, 
year={2007},
keywords={data mining;learning (artificial intelligence);program diagnostics;program testing;software quality;data mining;static code attributes;defect predictor learning;McCabes versus Halstead;lines of code counts;resource-bound exploration;Data mining;Bayesian methods;Artificial intelligence;Software testing;System testing;Learning systems;Art;Software quality;Software systems;Financial management;Data mining detect prediction;McCabe;Halstead;artifical intelligence;empirical;naive Bayes.}, }
@inproceedings{bird09,
title={Fair and balanced?: bias in bug-fix datasets},
author={Bird, Christian and Bachmann, Adrian and Aune, Eirik and Duffy, John and Bernstein, Abraham and Filkov, Vladimir and Devanbu, Premkumar},
booktitle={Proceedings of the the 7th joint meeting of the European software engineering conference and the ACM SIGSOFT symposium on The foundations of software engineering},
pages={121--130},
year={2009},
organization={ACM}
}
@article{arcuri13parameterto,
  title={Parameter tuning or default values? An empirical investigation in search-based software engineering},
  author={Andrea Arcuri and Gordon Fraser},
  journal={Empirical Software Engineering},
  year={2013},
}
@inproceedings{commitguru,
 author = {Rosen, C. and Grawi, B. and Shihab, E.},
 title = {Commit Guru: Analytics and Risk Prediction of Software Commits},
 series = {ESEC/FSE 2015},
 year = {2015},
 keywords = {Risky Software Commits, Software Analytics, Software Metrics, Software Prediction},
} 
